# ðŸ¤– DOCRAG â€” Document Based RAG Agent

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://sashu14-docrag-app-i3gf29.streamlit.app/)

> **Live Demo â†’ [sashu14-docrag-app-i3gf29.streamlit.app](https://sashu14-docrag-app-i3gf29.streamlit.app/)**

A **Retrieval-Augmented Generation (RAG)** app for financial documents â€” answers questions **exclusively from your uploaded PDF** with citations, quotes, and confidence scores. Powered by **Groq** (`llama-3.3-70b-versatile`) and **FAISS** vector search.

---

## âš™ï¸ Pipeline

```
PDF Upload â†’ Extract (PyMuPDF) â†’ Chunk (500 tok / 50 overlap)
          â†’ Embed (MiniLM-L6)  â†’ FAISS cosine search
          â†’ Inject top-5 chunks â†’ Groq LLM â†’ Cited answer
```

## ðŸ“‹ Output Format

```
Answer:     [grounded answer â€” only from the document]
Source:     [Page X / Section Y]
Quote:      "[exact text from document]"
Confidence: XX%
```

## ðŸš€ Run Locally

```bash
git clone https://github.com/sashu14/DocRAG.git
cd DocRAG
pip install -r requirements.txt

# Add your Groq API key
echo 'GROQ_API_KEY=gsk_...' > .env

streamlit run app.py
```

## âœ¨ Features

| Feature | Detail |
|---|---|
| PDF parsing | PyMuPDF (any finance PDF) |
| Chunking | 500 tokens, 50 token overlap |
| Embedding | `all-MiniLM-L6-v2` (local, free) |
| Vector DB | FAISS (in-memory, fast) |
| LLM | `llama-3.3-70b-versatile` via Groq |
| Citations | Page + Section + direct quote |
| Confidence | 0â€“100% per answer |

## ðŸ”‘ API Key

Get a **free** Groq API key at [console.groq.com](https://console.groq.com)
